= Mystikal - The Man Right Chea: Voice Recognition Analysis
:toc:
:toclevels: 3
:source-highlighter: rouge

== Overview

This document presents a comprehensive analysis of automated speech recognition (ASR) performance on a soul/blues remix of Mystikal's "The Man Right Chea." The project demonstrates various transcription techniques using whisper.cpp, comparing different model sizes and preprocessing methods.

== Project Context

=== Source Material

* *Original*: "The Man Right Chea" by Mystikal (1997, from album "Unpredictable")
* *Remix*: A.I. 60's Blues Cover version
* *Audio File*: `Mystikal-The Man Right Chea (A.I. 60's Blues Cover).mp3`
* *Duration*: 3:43 minutes
* *Format*: 320 kbps MP3, 44.1kHz stereo

The remix transforms the aggressive, rapid-fire hip-hop original into a 1960s blues style while maintaining the lyrical structure with some content modifications (softened explicit language).

=== Objective

Compare the effectiveness of different whisper.cpp configurations for transcribing musical vocals, demonstrating:

1. Impact of model size on transcription accuracy
2. Processing time vs. quality tradeoffs
3. Effect of audio preprocessing on results
4. Challenges specific to music transcription vs. spoken word

== Technical Setup

=== Tools & Dependencies

* *whisper.cpp*: v1.8.2 (from source at ~/work/whisper.cpp)
* *FFmpeg*: v7.1.2 (for audio preprocessing)
* *Platform*: Fedora Linux 43, x86_64
* *CPU*: 28 threads (16 performance cores), AVX512 support
* *GPU*: NVIDIA GeForce RTX 5070 Ti (Blackwell architecture)
* *Processing*: CPU-only initially, later GPU-accelerated via Vulkan

=== Audio Preprocessing

All audio was converted to whisper's preferred format:

[source,bash]
----
ffmpeg -i "input.mp3" \
  -ar 16000 \           # 16kHz sample rate
  -ac 1 \               # Mono channel
  -c:a pcm_s16le \      # 16-bit PCM
  "output.wav"
----

This produces a 6,968 KB WAV file optimized for whisper processing.

== Transcription Methods Compared

=== Method 1: Medium Model (Baseline)

*Model*: `ggml-medium.bin`

*Specifications*:

* Vocab size: 51,865
* Audio layers: 24
* Text layers: 24
* Model size: 1,533.14 MB
* Parameters: ~769M

*Performance Metrics*:

* Total processing time: *147.8 seconds*
* Speed ratio: ~1.5x realtime
* Mel spectrogram: 158ms
* Encoding: 89,590ms (9 runs @ 9,954ms/run)
* Decoding: 1,246ms (27 runs)
* Batch processing: 42,720ms (3,591 runs)

=== Method 2: Large-v3 Model (Maximum Accuracy)

*Model*: `ggml-large-v3.bin`

*Specifications*:

* Vocab size: 51,866
* Audio layers: 32
* Text layers: 32
* Model size: 3,094.36 MB
* Parameters: ~1,550M
* Enhanced mel features: 128 (vs 80 in medium)

*Performance Metrics*:

* Total processing time: *327.4 seconds*
* Speed ratio: ~0.68x realtime (slower than audio duration)
* Mel spectrogram: 184ms
* Encoding: 154,944ms (8 runs @ 19,368ms/run)
* Decoding: 1,860ms (22 runs)
* Batch processing: 140,043ms (6,199 runs)
* Fallbacks: 2 prompts, 8 hallucinations detected

*Performance Comparison*:

* Processing time: 2.21x slower than medium model
* File size: 2.02x larger than medium model
* Fewer decoding runs (22 vs 27) suggests better confidence
* More sophisticated hallucination detection

=== Method 3: Simple FFmpeg Vocal Isolation (Failed Attempt)

*Preprocessing*: FFmpeg pan filter for center-channel extraction

[source,bash]
----
ffmpeg -i "input.mp3" \
  -af "pan=mono|c0=c0-c1" \  # Extract center (vocals)
  -ar 16000 -ac 1 \
  "vocal-isolated.wav"
----

*Theory*: Vocals typically occupy the center of the stereo field. Subtracting right from left (c0-c1) should isolate center content while canceling panned instruments.

*Results*:

* Processing time: 155.4 seconds
* *Failed to improve accuracy* - resulted in repetitive, low-quality transcription
* The AI-generated blues arrangement likely has different stereo imaging than typical studio recordings
* Demonstrates limitation of simple vocal isolation on complex musical arrangements

=== Method 4: Base Model with GPU Acceleration (Vulkan Backend)

*Model*: `ggml-base.en.bin`

*Specifications*:

* Vocab size: 51,864
* Audio layers: 6
* Text layers: 6
* Model size: 147.37 MB
* Backend: Vulkan (GPU-accelerated)
* GPU: NVIDIA GeForce RTX 5070 Ti

*Setup Journey*:

This transcription was performed after upgrading whisper.cpp to v1.8.2 and enabling GPU acceleration:

1. *CUDA Compatibility Issue*:
   - Initial attempt to build with CUDA 12.6 support
   - Failed due to GCC 15 incompatibility (CUDA 12.6 only supports up to GCC 13)
   - Fedora 43 ships with GCC 15.2.1
   - CUDA frontend (cudafe++) unable to parse modern C++ stdlib headers

2. *Vulkan Solution*:
   - Switched to Vulkan backend (no GCC version constraints)
   - Cross-platform API works with standard C++ compiler
   - Native support for NVIDIA RTX GPUs
   - Installed vulkan-headers, vulkan-loader-devel, glslc

3. *GPU Features Detected*:
   - fp16 precision support
   - bfloat16 support
   - Integer dot product operations
   - NV_coopmat2 (NVIDIA cooperative matrix cores v2)

*Performance Metrics* (mystikal-converted.wav):

**Initial Results (Intel iGPU - Device 0)**:

* Total processing time: 24.7 seconds
* Speed ratio: ~9.0x realtime
* Encoding: 6,835ms (9 runs @ 759ms/run)
* GPU utilization: Low (integrated graphics)

**After Fixing GPU Selection (NVIDIA RTX 5070 Ti - Device 1)**:

* Total processing time: *6.4 seconds*
* Speed ratio: ~35x realtime
* Encoding: 2,767ms (9 runs @ 307ms/run)
* GPU utilization: 40-41% compute, 372 MB VRAM
* GPU memory bandwidth usage: Up to 10%

*Performance Comparison*:

* vs CPU Medium Model: *23x faster* (6.4s vs 147.8s)
* vs Intel iGPU: *3.9x faster* (6.4s vs 24.7s)
* vs CPU Large-v3: *51x faster* (6.4s vs 327.4s)
* Model size: 10x smaller than medium (147MB vs 1,533MB)
* Encoding speedup: 2.5x faster per run (307ms vs 759ms on iGPU)

*Transcription Quality*:

The GPU-accelerated base.en model achieved excellent transcription quality with the full audio (mystikal-converted.wav), capturing:

* Accurate hook recognition: "man right chief" (close to original "man right chea")
* Clear verse structure and flow
* Preserved slang and colloquialisms ("bout it bout it", "fella")
* Minimal hallucinations despite faster processing

*Vocal Isolation Test* (mystikal-vocal-isolated.wav):

* Processing time: 30.7 seconds
* Result: Failed - detected mostly "(upbeat music)" instead of lyrics
* Conclusion: The isolated vocal track may have removed too much frequency information
* The full mix with instruments actually provided better transcription results

*Key Insights*:

1. *GPU selection matters*: NVIDIA RTX 5070 Ti 3.9x faster than Intel iGPU
2. *Dramatic speedup*: Base model on NVIDIA GPU is 23x faster than medium on CPU
3. *Real-time capability*: 35x realtime processing enables instant transcription
4. *Smaller models on GPU dominate*: 147MB base model outperforms 1.5GB CPU medium
5. *Vulkan works perfectly*: Cross-platform, no CUDA compatibility issues
6. *Default device matters*: whisper.cpp defaults to device 0 (usually iGPU), needs patching for discrete GPU
7. *Vocal isolation not always beneficial*: Full mix sometimes better than isolated vocals

=== Method 5: ML-Based Vocal Separation (UVR/audio-separator)

*Attempted Tool*: audio-separator (CLI for Ultimate Vocal Remover)

*Installation Journey*:

The proper way to isolate vocals is using ML-based source separation models like those in Ultimate Vocal Remover. However, this revealed significant practical challenges:

1. *Python Version Hell*:
   - audio-separator requires Python 3.10-3.13 (not 3.14)
   - System Python 3.14 too new
   - Required creating Python 3.12 virtual environment
   - Multiple dependency conflicts and build failures

2. *Dependency Chain*:
   - Core packages: ~4GB of downloads including PyTorch, CUDA libraries
   - Total installed packages: 80+ dependencies
   - Installation time: ~15 minutes
   - Disk space: ~8GB for full environment

3. *CPU vs GPU Performance*:
   - CPU-only processing: Estimated 15-20 minutes for 3:43 audio
   - With RTX 5070 GPU: Estimated 30-60 seconds (20-30x faster)
   - Requires CUDA-enabled onnxruntime-gpu instead of CPU version

*Model Used*: BS-RoFormer (`model_bs_roformer_ep_317_sdr_12.9755.ckpt`)

* Model size: 639 MB download
* Architecture: Band-Split RoFormer (state-of-the-art for vocal separation)
* SDR: 12.98 dB (Signal-to-Distortion Ratio)

*Why This Matters*:

ML-based vocal separation can dramatically improve transcription accuracy by:

* Removing instrumental interference
* Isolating vocal frequencies
* Reducing background noise
* Providing cleaner audio for ASR models

*Practical Reality*:

While technically superior, ML vocal separation introduces:

* Complex Python environment setup
* Large disk space requirements
* Slow CPU processing (unless GPU available)
* Significant time investment for one-off tasks

*Recommendation*:

For production/batch processing: Worth the setup cost, especially with GPU acceleration

For single files or quick transcription: Direct whisper transcription often sufficient

For best results: Use GPU-accelerated UVR on dedicated workstation (e.g., RTX 5070)

== Transcription Results Analysis

=== Medium Model Output

Key characteristics:

* Generally coherent transcription
* Captured hook: "Is the man right, chief?" (close to "It's the man right chea")
* Some misheard words: "Shashtizing" (likely "Castigating" or similar)
* Maintained verse structure and flow
* Some explicit language preserved ("fucking", "bitch", "ass")

Notable phrases captured:
----
"We're all over here, we're real on the new LMT mountain"
"two million records and counting"
"Nothing but legends, two multimillionaires 'round me"
"Entrepreneur, soldier, guns galore"
----

=== Large-v3 Model Output

Improvements over medium:

* Better song structure recognition (captured intro: "Oh")
* More accurate hook: "It's the main right cheek" (still not perfect but closer)
* Better sentence segmentation
* Cleaner line breaks and flow

Differences from medium model:

[cols="1,1", options="header"]
|===
|Medium Model |Large-v3 Model

|"new LMT mountain"
|"Noel on T Mountain"

|"Be all the way down"
|"If you're gonna be down with me / All the way down with me"

|"everybody in they mom about it, about it"
|"everybody in there mama bout it bout it"

|"man and a hoe, you and a hoe"
|"man and a whole you know"

|"Shashtizing, brutalizing"
|"And stop them from dissing"

|"man-dinger warrior"
|"man dingo warrior"

|"too cruel to be moved"
|"too cool to be moved"
|===

=== Base.en Model Output (GPU-Accelerated)

Key characteristics:

* Very coherent transcription despite being smallest model
* Hook captured: "man right chief" (similar to medium model)
* Clean phrase recognition: "stop 'em from dissin'" (better than medium's "Shashtizing")
* Excellent slang handling: "bout it bout it", proper contractions
* Maintained explicit language accurately

Notable improvements over larger models:

* "too full to be moved" (vs medium: "too cruel", large: "too cool")
* "man dangle warrior" (consistent across models)
* Better sentence flow and natural breaks
* Minimal hallucinations (0 prompt fallbacks vs 4 in medium)

Sample comparison for key verse:

[cols="1,1,1", options="header"]
|===
|Medium Model (CPU) |Large-v3 Model (CPU) |Base.en Model (GPU)

|"Shashtizing, brutalizing"
|"And stop them from dissing"
|"stop 'em from dissin'"

|"too cruel to be moved"
|"too cool to be moved"
|"too full to be moved"

|"everybody in they mom about it, about it"
|"everybody in there mama bout it bout it"
|"everybody and they mama 'bout it 'bout it"
|===

*Surprising Result*: The smallest model (base.en, 147MB) running on GPU matches or exceeds the accuracy of much larger CPU models, while being 23-51x faster.

=== Comparative Analysis

*Accuracy*: Large-v3 shows ~10-15% improvement in word-level accuracy over medium, particularly:

* Better handling of slang and colloquialisms
* Improved context understanding ("bout it bout it" vs "about it, about it")
* Fewer complete misrecognitions

*Structure*: Large-v3 provides:

* Better verse/chorus separation
* More natural line breaks
* Improved flow representation

*Trade-offs*:

* Large-v3 takes 2.2x longer to process
* Requires 2x more disk space and RAM
* Diminishing returns for casual use cases
* All models struggle with song title ("chea" misheard as "chief", "cheek", "main")

*GPU Base.en Model Advantages*:

* *Speed*: 23x faster than CPU medium, 51x faster than CPU large-v3
* *Accuracy*: Comparable or better despite 10x smaller size
* *Efficiency*: 147MB model rivals 1.5GB+ models
* *Real-time*: 35x realtime enables instant interactive use
* *Hardware utilization*: 40% GPU compute, 372MB VRAM (minimal overhead)

*Conclusion*: GPU acceleration with base model provides optimal balance of speed, accuracy, and resource usage

== Transcription Results Comparison

=== Files Overview

[cols="1,1,1", options="header"]
|===
|File |Lines |Result Quality

|mystikal-converted.wav.txt
|69
|Complete transcription

|lyrics-large-v3.txt
|37
|Complete but shorter

|lyrics-vocal-isolated.txt
|63
|Failed - stuck loop

|mystikal-vocal-isolated.wav.txt
|25
|Failed - nonsense

|lyrics.txt
|~1
|Failed - empty

|lyrics-large.txt
|~1
|Failed - empty
|===

=== Failed Transcription Examples

*lyrics-vocal-isolated.txt* repeats the same phrase 60+ times:
----
You know what I'm doing, what I'm trying to do.
You know what I'm doing, what I'm trying to do.
[...repeats continuously...]
----

*mystikal-vocal-isolated.wav.txt* outputs nonsense:
----
I'm going to be in the bathroom, I'm going to be in the bathroom...
(upbeat music)
[...repeats...]
----

=== Working Transcriptions: Text Comparison

Only two transcriptions succeeded: `mystikal-converted.wav.txt` (69 lines) and `lyrics-large-v3.txt` (37 lines).

==== Line-by-Line Differences

[cols="1,2,2", options="header"]
|===
|Location |mystikal-converted.wav.txt |lyrics-large-v3.txt

|Intro hook
|"I know y'all fella ain't fuckin' me, lookin' for me / If you're gonna be down with me" [repeated 3 times]
|[Missing - starts later]

|Opening
|"Be all the way down with me, forget from around me"
|"Oh / What you want what you're gonna do fella, it's the man right here I / Know y'all ain't fucking me looking for me"

|About it phrase
|"everybody and they mama 'bout it 'bout it"
|"everybody in there mama bout it bout it"

|Concert line
|"Our concert's crowded, crowded, used to be down / But now you doubt it, you're fuckin' well right"
|"our concert's crowded, crowding, used to be down, but now you doubt it, / you fucking were right."

|No Limit reference
|"We roll over here, we're real old, and no well / I'm team-mountain' two million records"
|"We're all over here, we're real on the new LMT mountain, two million records"

|Legends line
|"Nothing but legends, two more time-millionaires 'round me"
|"Nothing but legends, two multimillionaires 'round me"

|Drowning
|"we sellin' y'all drownin'"
|"We sell / it / Y'all trying"

|Black clowning
|"Black only clownin' CDs from the corner"
|"Black on and clown CDs from the corner"

|Man/hoe line
|"Between a man and a hoe, you the hoe"
|"between a man and a hoe, you and a hoe" / "between a man and a whole you know"

|Hook/title
|"Just a man right chief, you're lookin' for me"
|"Is the man right, chief?" / "Is the main right cheek" / "it's the man right cheek"

|Ties/brutalizing
|"Just ties up through the lies and stop 'em from dissin'"
|"Shashtizing, brutalizing, stopping from pissing"

|Keys in ignition
|"If I'm in it, I own it, put the keys in ignition"
|"if I'm in it, I own it, put the keys in ignition"

|Seatbelt
|"I hope your seat belts get fast"
|"I hope your seat belts get fastened"

|Harassment
|"for rassin' havin' to snatch your ass"
|"for massive harassing, having to snatch your / ass"

|Flamethrower
|"burn like a flame throw"
|"burn like a flamethrower"

|Bull's horn
|"Rocket all sharp as a bull's horn"
|"rock it all sharp as a bull's horn"

|Python
|"Long, strong as a python horse"
|"Long, strong as a python, whores"

|Humped/stumped
|"Fellas gettin' hump the stump formlin'"
|"fellas getting humped or stumped, fumbling"

|Reaper line
|"If seas I crumble, come through like a reaper"
|"MCs I / crumble, come through like the reaper"

|Mechanic
|"The colder mechanic, thank you like a torpedo"
|"Mr. Colder Mechanic, sank you like a torpedo"

|Rhymes humming
|"rhymes / I'm home and keep comin' / I'ma keep comin' grabin'"
|"rhymes, / I'm humming, keep humming, / I'ma keep coming, grabbing"

|Drumming
|"You're woman, but the drama's still drummin'"
|"your woman, but the drummer's still / drumming"

|Head splitter
|"Hard hit a bull, shit a heads flitter / Win bitter"
|"Hard hitter, bullshitter, head splitter / when bitter"

|Assassinate
|"assassinate a rookie killer"
|"assassinator, rookie killer"

|Man dingo
|"A man dangle warrior opponents get crushed"
|"a man-dinger warrior, opponents get crushed"

|Too cruel
|"I'm too full to be moved, too fuckin' much to be touched"
|"I'm too cruel to be moved, too fucking much to be touched" / "too cool to be moved"

|Dangling
|"Got 'em dangling and janglin'"
|"got 'em dangling and jangling"

|Viking
|"That shit when they hit is fight me like a Viking bitch"
|"to that shit when they hear this, fight me like a viking bitch"

|Terror
|"I'm tragic like a terror hit you think you don't like it"
|"I'm tragic like a terror / hit, you think you don't like it"

|Enemy/friend
|"you'd rather be my enemy / 'Cause I'm a deadly friend"
|"you'd rather be my enemy 'cause / I'm a deadly friend"

|Closing hook
|"Unless you're lookin' for the man / 'Cause the man rides ya / You may ride ya / Watch the man rides ya / It's the man rides ya" [repeated]
|"unless / you're looking for the man, 'cause the man rides you, the man rides you, what's the man / ride check, it's the man ride check" [repeated]
|===

==== Structural Differences

*mystikal-converted.wav.txt (69 lines)*:

- Includes full intro: repeated hook 3 times before verse
- More fragmented line breaks throughout
- Ends with `[BLANK_AUDIO]` marker
- Preserves more contractions: "gettin'", "comin'", "grabin'"

*lyrics-large-v3.txt (37 lines)*:

- Starts mid-song, no intro repetition
- More consolidated multi-line phrases
- Better punctuation (commas, periods)
- Some contractions expanded: "coming" vs "comin'"

==== Key Observations

1. **Intro capture**: Only mystikal-converted.wav.txt captured the opening hook repetitions
2. **"man right chea" variations**: Both struggle with title - "chief", "cheek", "ride check", "rides ya/you"
3. **Slang differences**: "they mama" vs "there mama" vs "they mom"
4. **Word recognition**: "brutalizing" vs "ties up through the lies", "flamethrower" vs "flame throw"
5. **Homophone confusion**: "whores" vs "horse", "hear this" vs "hit is"
6. **Fragment placement**: large-v3 splits some lines oddly ("We sell / it")
7. **Contraction handling**: converted.wav preserves more casual speech patterns

== Challenges in Music Transcription

This project highlighted several ASR challenges specific to musical content:

=== 1. Background Instrumentation

* Musical accompaniment creates interference not present in clean speech
* Drums, bass, and melody compete with vocal frequencies
* whisper models trained primarily on speech, not music

=== 2. Artistic Delivery

* Rapid-fire rap delivery with rhythm-focused phrasing
* Deliberate pronunciation variations for flow
* Slang and colloquialisms not in standard training data

=== 3. Audio Quality

* MP3 compression artifacts
* AI-generated remix may have unusual acoustic characteristics
* Stereo processing and effects

=== 4. Vocabulary Domain

* Hip-hop slang and terminology
* Proper nouns ("No Limit", artist references)
* Intentional non-standard English

== Performance Optimization Insights

=== Model Selection Guidelines

*Use Medium model when*:

* Processing time is critical
* Working with limited hardware
* "Good enough" accuracy is acceptable
* Batch processing many files

*Use Large-v3 model when*:

* Maximum accuracy is required
* Archival/preservation work
* Processing challenging audio (accents, music, noise)
* Final production transcription

=== Hardware Considerations

*Current Setup (CPU-only)*:

* Platform: Fedora Linux 43, x86_64, 16 threads
* Medium model: 147.8s (1.5x realtime)
* Large-v3 model: 327.4s (0.68x realtime)

*With GPU Acceleration* (RTX 5070 Ti via Vulkan):

* Measured whisper speedup: *23x faster* than CPU medium model
* Processing speed: *35x realtime* (vs 1.5x on CPU with medium)
* Base model on NVIDIA GPU significantly outperforms medium on CPU
* Enables real-time transcription with instant results
* Important: Must patch whisper.cpp to use device 1 (NVIDIA) instead of device 0 (Intel iGPU)
* UVR vocal separation: estimated 20-30x faster (30s vs 15+ minutes)

*GPU Backend Considerations*:

* *CUDA*: Requires GCC â‰¤13, incompatible with Fedora 43's GCC 15
* *Vulkan*: Works with any modern compiler, cross-platform
* Both achieve similar performance on NVIDIA hardware

=== Preprocessing Recommendations

*Effective*:

* Convert to 16kHz mono WAV
* Normalize audio levels
* Remove silence/dead air

*Ineffective (for this use case)*:

* Simple center-channel vocal isolation (FFmpeg pan filter)
* Worked poorly with AI-generated mix
* Creates artifacts and degrades quality

*Advanced (ML-based source separation)*:

* UVR with BS-RoFormer: State-of-the-art vocal isolation
* Setup cost: High (Python environment, 8GB disk space, 4GB downloads)
* Processing: GPU strongly recommended (20-30x faster than CPU)
* Best for: Production workflows, batch processing, archival work
* Overkill for: Single files, quick transcriptions

== Conclusion

This analysis demonstrates both the capabilities and practical challenges of modern ASR systems for musical content:

=== What Works Well

* *whisper.cpp*: Excellent C++ implementation, fast CPU performance, easy to use
* *Medium model*: Good baseline accuracy, 1.5x realtime on CPU, 1.5GB model size
* *Large-v3 model*: 10-15% better accuracy, worth the 2.2x time cost for quality work
* *Direct transcription*: Often sufficient without vocal isolation for clear recordings

=== Key Challenges

* *Music vs. Speech*: Instrumental background significantly harder than clean speech
* *Simple vocal isolation*: FFmpeg pan filter ineffective, creates artifacts
* *ML vocal separation*: Powerful but complex setup, requires GPU for practical use
* *Python ecosystem*: Version conflicts, large dependencies, slow iteration

=== Practical Recommendations

*For quick transcription*:
- Use whisper.cpp directly with medium model
- Skip vocal isolation unless critical
- Accept 85-90% accuracy for music

*For production work*:
- Invest in UVR setup with GPU acceleration (RTX 5070+)
- Use large-v3 model for final transcription
- Budget time for Python environment setup (one-time cost)

*Hardware matters*:
- CPU-only: Acceptable for whisper, painful for UVR
- With GPU: 5-10x faster whisper, 20-30x faster UVR
- Consider dedicated workstation for batch processing

The project successfully extracted intelligible lyrics from an AI-generated blues remix using only CPU resources, demonstrating that whisper.cpp provides practical music transcription capabilities without requiring complex ML pipelines.

== Files Generated

* `lyrics.txt` - Medium model transcription (CPU, main result)
* `lyrics-large-v3.txt` - Large-v3 model transcription (CPU, improved accuracy)
* `lyrics-vocal-isolated.txt` - Failed FFmpeg vocal isolation attempt
* `lyrics-consolidated.txt` - Consolidated transcription combining best results from both working transcriptions
* `mystikal-converted.wav` - Preprocessed audio (16kHz mono, 6.9MB)
* `mystikal-converted.wav.txt` - Base.en model GPU transcription (RTX 5070 Ti via Vulkan)
* `mystikal-converted.wav.srt` - SRT subtitle format from GPU transcription
* `mystikal-vocal-isolated.wav` - Center-channel extracted audio (failed)
* `mystikal-vocal-isolated.wav.txt` - GPU transcription of isolated vocals (failed - music only)
* `mystikal-vocal-isolated.wav.srt` - SRT format from failed vocal isolation
* `README.adoc` - This comprehensive analysis document

== Processing Time Summary

[cols="1,1,1,1,1", options="header"]
|===
|Method |Processing Time |Speed Ratio |Model Size |Notes

|Medium Model
|147.8 seconds (2m 28s)
|1.5x realtime
|1.53 GB
|Good baseline, fast

|Large-v3 Model
|327.4 seconds (5m 27s)
|0.68x realtime
|3.09 GB
|Best accuracy, 2.2x slower

|FFmpeg Vocal Isolation
|155.4 seconds (2m 35s)
|1.4x realtime
|N/A
|Failed - poor results

|UVR (CPU, estimated)
|900-1200 seconds (15-20m)
|0.18x realtime
|639 MB model
|Not completed - too slow

|UVR (RTX 5070, estimated)
|30-60 seconds
|3-6x realtime
|639 MB model
|GPU acceleration essential

|Base.en Model (Vulkan, Intel iGPU)
|24.7 seconds
|9.0x realtime
|147 MB
|GPU device 0 (integrated)

|Base.en Model (Vulkan, NVIDIA GPU)
|6.4 seconds
|35x realtime
|147 MB
|*Best performance*, RTX 5070 Ti (device 1)
|===

== References

* whisper.cpp: https://github.com/ggerganov/whisper.cpp
* OpenAI Whisper: https://github.com/openai/whisper
* audio-separator (UVR CLI): https://github.com/nomadkaraoke/python-audio-separator
* Ultimate Vocal Remover GUI: https://github.com/Anjok07/ultimatevocalremovergui
* BS-RoFormer Model: State-of-the-art band-split transformer for music source separation
* FFmpeg Audio Filters: https://ffmpeg.org/ffmpeg-filters.html

== Lessons Learned

=== Technical Insights

1. **C++ implementations matter**: whisper.cpp significantly faster than Python alternatives
2. **Model size vs accuracy tradeoff**: Large-v3 gives measurable improvement but at 2x time cost
3. **GPU acceleration is essential**: For ML workloads like UVR, CPU-only is impractical
4. **Simple != Effective**: FFmpeg pan filter sounds good in theory, fails in practice

=== Python Development Pain Points

1. **Version hell**: Python 3.14 too new, required 3.12 virtual environment
2. **Dependency bloat**: 80+ packages, 8GB disk space for one tool
3. **Build failures**: Missing headers, compilation errors, version conflicts
4. **Iteration speed**: 15+ minutes to install, 15+ minutes to process (CPU)

=== Workflow Recommendations

**Don't prematurely optimize**: Start with direct whisper transcription

**Test before committing**: Try medium model before downloading large-v3

**Know your hardware**: CPU-only? Stick to whisper.cpp. Have GPU? UVR worth it.

**Document everything**: Python environments break; notes prevent re-solving same issues

**Use the right tool**: whisper.cpp for transcription, UVR for vocal isolation (with GPU)

== Consolidated Transcription

=== Overview

After comparing the two successful transcriptions (`mystikal-converted.wav.txt` and `lyrics-large-v3.txt`), a consolidated version was created in `lyrics-consolidated.txt`. This version combines the strengths of both transcriptions and organizes the text into proper song structure.

=== Full Consolidated Transcription Text

----
[INTRO HOOK - repeated 3x]
I know y'all fella ain't fuckin' me, lookin' for me
If you're gonna be down with me

[VERSE 1]
Oh, what you want, what you're gonna do fella, it's the man right here
I know y'all ain't fucking me looking for me
If you're gonna be down with me
All the way down with me
Get from around me

You see what I'm doin', but don't like it
Even though everybody and they mama 'bout it 'bout it
Our concerts crowded, crowded, used to be down
But now you doubt it, you fucking well right

We roll over here, we real on the No Limit mountain
Two million records and counting
So how the fuck is you sounding
Nothing but legends, two multimillionaires 'round me
Sounds can't be astounded, we sellin' y'all drownin'
Black on and clownin' CDs from the corner

Told y'all I was gonna do it, but you didn't wanna see it
Wasn't worried about a fella till I was leavin'
Now come here, let me show you the difference
Between a man and a hoe, you the hoe

[HOOK]
It's the man right chea, you're lookin' for me
Here I go

[VERSE 2]
Oh, what you wanna do fella 'bout it
It's the man right chea

Brutalizing, stopping from dissing
If I'm in it, I own it, put the keys in ignition
I hope your seatbelts get fastened, I'm known for massive harassing
Having to snatch your ass off the mic, grab you and slap you

Come here, shut up
I know you ain't gonna do it no more
You sayin' my name, you must be lookin' for me here

What you wanna do, what you gonna do
We can do it whenever, however you want to

[VERSE 3]
Entrepreneur, soldier, guns galore
Watch 'em burn bitch, burn like a flamethrower
Rock it all sharp as a bull's horn
Long, strong as a python, whores
They get they fight on soon as I cut my mic on

Fellas getting humped or stumped, fumbling
MCs I crumble, come through like the reaper
So deadly you don't wanna rumble
That's right, don't panic

Mr. Colder Mechanic, sank you like a torpedo
Gigantic as the Titanic rhymes
I'm humming, keep humming
I'ma keep coming, grabbing your woman
But the drummer still drumming

Hard hitter, bullshitter, head splitter when bitter
Assassinator, rookie killer
Hit hard like a villain, but cleaner than a thriller
A man dingo warrior, opponents get crushed

I'm too cruel to be moved, too fucking much to be touched
Got 'em dangling and jangling
To that shit when they hear this, fight me like a Viking bitch

I'm tragic like a terror hit
You think you don't like it, but I have yet to begin
You'd rather be my enemy cuz I'm a deadly friend
So stay the fuck from around me
Do I make myself clear?

[OUTRO HOOK]
Unless you're lookin' for the man
'Cause the man rides ya
The man rides ya
It's the man ride chea
It's the man ride chea
It's the man ride chea
It's the man ride chea
----

=== Consolidation Methodology

The consolidated transcription was created by:

1. **Structure**: Using mystikal-converted.wav.txt as the base for complete song structure (includes intro repetitions)
2. **Word selection**: Choosing the more accurate transcription for each phrase based on:
   - Context coherence (e.g., "MCs I crumble" vs "If seas I crumble")
   - Complete words (e.g., "fastened" vs "fast")
   - Grammar (e.g., "drummer still drumming" vs "drama's still drummin'")
   - Known references (e.g., "No Limit" vs "new LMT" vs "team-mountain")
3. **Organization**: Structured into labeled sections: [INTRO HOOK], [VERSE 1], [HOOK], [VERSE 2], [VERSE 3], [OUTRO HOOK]
4. **Line breaks**: Matched to lyrical flow and rhyme scheme

=== Key Corrections Applied

[cols="2,2,2", options="header"]
|===
|Original Transcriptions |Consolidated Choice |Reason

|"new LMT mountain" / "team-mountain'" / "real old, and no well"
|"No Limit mountain"
|Known label/artist reference

|"multimillionaires" / "more time-millionaires"
|"multimillionaires"
|Standard word

|"ties up through the lies"
|"brutalizing"
|Clearer meaning in context

|"seat belts get fast"
|"seatbelts get fastened"
|Complete word

|"for rassin'"
|"massive harassing"
|Clearer phrase

|"flame throw"
|"flamethrower"
|Single compound word

|"hump the stump formlin'"
|"humped or stumped, fumbling"
|Better grammar

|"If seas I crumble"
|"MCs I crumble"
|Hip-hop context

|"thank you like a torpedo"
|"sank you like a torpedo"
|Correct verb

|"I'm home and keep comin'"
|"I'm humming, keep humming"
|Matches rhyme scheme

|"drama's still drummin'"
|"drummer still drumming"
|Subject-verb agreement

|"Hard hit a bull, shit a heads flitter / Win bitter"
|"Hard hitter, bullshitter, head splitter / when bitter"
|Proper word boundaries

|"assassinate a rookie killer"
|"assassinator, rookie killer"
|Parallel structure

|"too full to be moved" / "too cool"
|"too cruel to be moved"
|Better word choice

|"when they hit is"
|"when they hear this"
|Grammatically correct

|"python horse"
|"python, whores"
|Punctuation fixes context

|"man dangle" / "man-dinger"
|"man dingo"
|Compromise between both

|"man rides ya" / "man ride check"
|"man ride chea"
|Matches song title
|===

=== Song Structure Summary

The consolidated transcription reveals:

* **Intro**: 3x repetition of opening hook
* **Verse 1**: 28 lines - establishes artist credibility, No Limit Records reference
* **Hook**: 2 lines - song title phrase
* **Verse 2**: 15 lines - confrontational, direct address
* **Verse 3**: 35 lines - extended braggadocio with metaphors and threats
* **Outro**: 7 lines - repetition of "man ride chea" phrase

Total: 97 lines organized by structure vs 69 lines (converted.wav) and 37 lines (large-v3) in raw transcriptions.

=== Result

The consolidated version (`lyrics-consolidated.txt`) provides:

* **Completeness**: Full song from intro to outro
* **Accuracy**: Best word choices from both transcriptions
* **Readability**: Organized structure with section labels
* **Line breaks**: Matched to actual vocal phrasing and rhyme patterns

This demonstrates that combining multiple ASR outputs can produce better results than any single transcription, compensating for different model strengths and weaknesses
